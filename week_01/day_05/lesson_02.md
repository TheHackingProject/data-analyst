# Le Big Data
A quoi correspond techniquement cette rÃ©volution qu'on appelle communÃ©ment "Big Data" et quelles sont ses consÃ©quences sur l'analyse de donnÃ©es ?

## 1. Introduction
Tu viens de voir les deux familles d'outils indispensables Ã  la Data Analyse : les langages de programmation et les bases de donnÃ©es ğŸ‘ğŸ‘ Il te reste Ã  voir encore deux familles d'outils : les outils d'analyse (que tu verras lors de la troisiÃ¨me semaine de la formation) et les outils Big Data, qu'on va voir dans cette ressource. Les outils Big Data sont apparus rÃ©cemment et sont souvent gÃ©rÃ©s par des devs vue leur complexitÃ©. Mais il est important pour toi de comprendre leur utilitÃ© et leur fonctionnement.

## 2. Historique et contexte
On peut dater lâ€™acte de naissance du big data en 2001 avec lâ€™invention de la rÃ¨gle des 3V (Volume, Vitesse et VariÃ©tÃ©). A lâ€™Ã©poque, lâ€™expression traduisait une rupture dans le volume des donnÃ©es Ã  traiter. Jusquâ€™Ã  la fin des annÃ©es 90, les quantitÃ©s de donnÃ©es restaient limitÃ©es. Puis, on a assistÃ© Ã  une explosion du volume de donnÃ©es avec lâ€™essor de lâ€™e-commerce, des rÃ©seaux sociaux, des terminaux mobiles et, plus rÃ©cemment, de lâ€™internet des objets (IoT). Face Ã  cette avalanche de data, les modÃ¨les techniques existants ont montrÃ© leurs limites. La base de donnÃ©es parfaite nâ€™existait plus. En fonction du souhait de privilÃ©gier la volumÃ©trie, la vitesse ou les capacitÃ©s de requÃªtage, on choisira une solution plutÃ´t quâ€™une autre ou bien une combinaison dâ€™outils.

Pour leurs propres besoins, les GAFAM ont dÃ» crÃ©er des outils pour stocker et traiter Ã  la volÃ©e des donnÃ©es Ã  la fois nombreuses et versatiles, leur structuration changeant avec le temps. Facebook est ainsi Ã  lâ€™origine de Cassandra avant de se tourner vers HBase (NoSQL), Google de BigTable et GFS (ancÃªtre dâ€™HDFS) et plus rÃ©cemment de TensorFlow (machine learning). Les gÃ©ants du web ont ensuite versÃ© ces projets en open source, externalisant en quelque sorte leur R&D. Car Ã  leurs yeux, lâ€™or ce sont les donnÃ©es elles-mÃªmes, pas les technologies. 
 
Finalement, aprÃ¨s avoir Ã©tÃ© longtemps un buzzword, "Big Data" a repris son sens premier : il fait rÃ©fÃ©rence Ã  l'ensemble des technologies comme Hadoop, Spark, les bases de donnÃ©es NoSQL ... que tu vas dÃ©couvrir aujourd'hui.

## 3. La ressource

L'univers du Big Data est complexe et pourrait faire l'objet de plusieurs semaines de formation. Mais dans ton cas de futur Data Analyst, une journÃ©e suffira car tu as surtout besoin d'avoir les bases pour pouvoir ensuite naviguer dans un projet Big Data. En fait, ce n'est pas toi qui devras crÃ©er les infrastructures Big Data, c'est le rÃ´le du *Data Engineer* ou *Data Architect*. On va donc te livrer ici les notions les plus importantes pour comprendre le Big Data.

https://matheo.uliege.be/bitstream/2268.2/2562/4/M%C3%A9moire%20Camille%20Marenne.pdf

https://inventiv-it.fr/big-data-devez-apprendre/

https://www.atys-concept.com/blog-de-la-performance/articles-performance-industrielle/differences-entre-data-analytics-data-science-big-data/

https://www.decideo.fr/Les-6-competences-les-plus-recherchees-en-Big-Data_a10051.html


### 3.1. Big data is not only big !

On pourrait penser que le Big Data (mÃ©gadonnÃ©es en franÃ§ais) se rÃ©sume Ã  des gros volumes de donnÃ©es. Mais sans parler de Big Data, il est aujourdâ€™hui possible de stocker et dâ€™exploiter de trÃ¨s gros volumes de donnÃ©es avec une grande variÃ©tÃ© de sources dans de grands entrepÃ´ts de donnÃ©es (les *Data Warehouses*). En effet, les technologies actuelles permettent de traiter des gros volumes de donnÃ©es selon les mÃ©thodes analytiques de Business Intelligence sans avoir recours au Big Data (cf. la ressource prÃ©cÃ©dente).

Si le Big Data concerne effectivement des gros volumes de donnÃ©es, une de ses spÃ©cificitÃ©s est de sâ€™intÃ©resser aussi bien aux donnÃ©es structurÃ©es quâ€™aux donnÃ©es non structurÃ©es. Ce sont les donnÃ©es non structurÃ©es que les outils habituels dâ€™analytique ne savent pas traiter. Une autre spÃ©cificitÃ© est le stockage des donnÃ©es, qui ne sont plus stockÃ©es dans des *Data Warehouses* mais dans des *Data Lakes*. Finalement, plus que les volumes, ce qui fait le Big Data est donc la nature des donnÃ©es, la maniÃ¨re dont on les stocke et les techniques dâ€™analyse pratiquÃ©es avec des savoir-faire et des technologies propres.

En fait, au tout dÃ©but, on a parlÃ© des 3V : volume (grandes quantitÃ©s), variÃ©tÃ© (diffÃ©rents types de donnÃ©es) et vÃ©locitÃ© (rapiditÃ© de traitement). Mais ce que lâ€™acronyme des 3V ne mettait pas en perspective, câ€™Ã©tait cette innovation centrale qui veut que **les donnÃ©es nâ€™ont pas besoin dâ€™Ãªtre systÃ©matiquement Â« transformÃ©es Â» pour Ãªtre analysÃ©es**. Apparaissait donc une nouvelle approche, trÃ¨s diffÃ©rente de l'approche ETL oÃ¹ La donnÃ©e est structurÃ©e et convertie Ã  des formats prÃ©cis. 

âš ï¸âš ï¸ Ne croyez pas pour autant que les big data rendent les *data warehouses* obsolÃ¨tes. Les systÃ¨mes de big data vous amÃ¨nent Ã  travailler avec des donnÃ©es non structurÃ©es, mais le type de rÃ©sultats de requÃªtes que vous obtenez est loin de la sophistication des *data warehouses*. La *data warehouse* est conÃ§ue pour une analyse en profondeur de la donnÃ©e, et cela est rendu possible prÃ©cisÃ©ment parce que la donnÃ©e a Ã©tÃ© transformÃ©e et prÃ©vue dans un format spÃ©cifique.

Le big data permet dâ€™analyser beaucoup plus de donnÃ©es de beaucoup plus de sources, mais avec une rÃ©solution moins fine. Pour schÃ©matiser, on peut dire que le big data est un monde impressionniste qui aura toujours besoin Ã  ses cÃ´tÃ©s de lâ€™hyper-rÃ©alisme des *data warehouses* ğŸ¨ Câ€™est pour cela que nous sommes condamnÃ©s Ã  vivre Ã  la fois avec les *data warehouses* traditionnelles  et ce nouveau style de traitement que sont les big data. Le big data ne consiste donc surtout pas Ã  dÃ©sapprendre ce que lâ€™on a appris en se formant au *data warehouse*. Le data scientist nâ€™a pas forcÃ©ment vocation Ã  prendre la place de lâ€™ingÃ©nieur en informatique dÃ©cisionnelle. Il faudra au contraire que lâ€™entreprise se pose la question de comment faire en sorte que les deux sâ€™enrichissent mutuellement. Et c'est aussi ces deux aspects que nous allons t'apprendre dans cette formation.

___

ğŸ’¡ğŸ’¡ AIDE MNÃ‰MOTECHNIQUE ğŸ’¡ğŸ’¡

Pour synthÃ©tiser, le Big Data c'est une famille d'outils qui rÃ©pondent non pas Ã  3 mais Ã  5Vs Ã  la fois : 
- **Volume** -> des ensembles de donnÃ©es trÃ¨s volumineux 
- **Vitesse** ou **VÃ©locitÃ©** -> la vitesse Ã  laquelle les donnÃ©es sont gÃ©nÃ©rÃ©es et Ã  laquelle elles se dÃ©placent
- **VariÃ©tÃ©** -> en fait, 80% des donnÃ©es dans le monde ne sont plus structurÃ©es et ne peuvent donc pas Ãªtre facilement mises dans des tables ou des bases de donnÃ©es relationnelles - pense Ã  des photos, des sÃ©quences vidÃ©os ou des mises Ã  jour de rÃ©seaux sociaux âŒšï¸ğŸ“±
- **VÃ©racitÃ©** -> les donnÃ©es sont devenues incertaines : il faut gÃ©rer la fiabilitÃ© de donnÃ©es intrinsÃ¨quement imprÃ©cises.
- **Valeur** -> finalement, tous ces volumes de donnÃ©es variÃ©es en mouvement rapide et de vÃ©racitÃ© diffÃ©rente doivent Ãªtre transformÃ©s en valeur ! C'est lÃ  l'enjeu majeur du Big Data âš–ï¸âš–ï¸

___


### 3.2. Les technos du Big Data

Trois grandes Ã©volutions techniques ont permis la crÃ©ation et la croissance du Big Data :

- Lâ€™Ã©volution du hardware de stockage capable de stocker de plus en plus de donnÃ©es, passant de serveurs physiques internes Ã  lâ€™entreprise Ã  des serveurs dit â€œcloudâ€ qui ont souvent une capacitÃ© de stockage bien supÃ©rieure.
- Le second point est une remise en cause du modÃ¨le matÃ©riel existant, celui oÃ¹ il fallait acheter le plus gros serveur possible. Aujourdâ€™hui, la nouvelle Ã©volution consiste Ã  mettre en sÃ©rie des petits serveurs remplaÃ§ables et de crÃ©er un systÃ¨me distribuÃ© rÃ©sistant aux pannes. Ce paradigme a Ã©tÃ© popularisÃ© par Google au dÃ©but des annÃ©es 2000 et est Ã  lâ€™origine de la premiÃ¨re version open source du premier framework Big Data sorti il y a 10 ans : Hadoop.
- La troisiÃ¨me rÃ©volution sâ€™est amorcÃ©e en 2009 et est lâ€™explosion des outils dâ€™analyse, dâ€™extraction et de traitement des donnÃ©es de maniÃ¨re non structurÃ©e que cela soit du NoSQL ou de nouveaux frameworks liÃ© Ã  lâ€™Ã©cosystÃ¨me de Hadoop.

Les bases de donnÃ©es classiques ne permettant plus de gÃ©rer de tels volumes, les grands acteurs du web (Facebook, Google, Yahoo, Linkedin, Twitter) ont crÃ©Ã© des Framework Big Data permettant de gÃ©rer et traiter des grandes quantitÃ©s de donnÃ©es Ã  travers, par exemple, des lacs de donnÃ©es. Ces donnÃ©es sont ensuite â€œsplittÃ©esâ€ ou sÃ©parÃ©es pour Ãªtre traitÃ©es parallÃ¨lement afin dâ€™allÃ©ger les processus de calcul (dans lâ€™ancien modÃ¨le, les traitements Ã©taient fait les uns aprÃ¨s les autres, dans un stack), puis rÃ©assemblÃ©es pour donner le rÃ©sultat final. Câ€™est cette technologie qui permet des vitesses de traitement aussi rapides sur de gros volumes de donnÃ©es. Au dÃ©part dÃ©veloppÃ©e par Google, elle est maintenant sous le drapeau Apache et sâ€™appelle Map Reduce.





#### 3.2.1 ModÃ¨le d'architecture







#### 3.2.1 MapReduce - algorithmes distribuÃ©s

Au dÃ©part, il y a eu **MapReduce**, une mÃ©thode et une technologie de traitement massivement parallÃ¨le issues des laboratoires Google Corp  avec gestion de la tolÃ©rance aux pannes et systÃ¨me de gestion de fichiers spÃ©cifiques (Google File System). On parle lÃ  de traitement sur des milliers de machines rÃ©parties en grappes (clusters). 

#### 3.2.2 Hadoop

#### 3.2.3 Spark 



#### 3.2.4 Le cloud computing

#### 3.2.5 Les bases de donnÃ©es NoSQL




## 4. Points importants Ã  retenir
Au-delÃ  des buzz words, l'analyse de donnÃ©es prend diffÃ©rentes formes et peut se rÃ©aliser Ã  diffÃ©rents niveaux. On peut distinguer deux types d'analyses : 
- l'analyse de donnÃ©es au travers de logiciels de *Business Intelligence* qui permet de faire parler les donnÃ©es, le plus souvent dÃ©jÃ  collectÃ©es et stockÃ©es dans lâ€™entreprise.
- lâ€™analytique Big Data qui nÃ©cessite lâ€™intervention de spÃ©cialistes et la mise en Å“uvre dâ€™une architecture informatique et dâ€™outils complexes. 


## 5. Pour aller plus loin


peut-Ãªtre mettre une blague ex : "si tu me crois pas qu'Hadoop est indispensable, cf https://www.decideo.fr/Les-6-competences-les-plus-recherchees-en-Big-Data_a10051.html"

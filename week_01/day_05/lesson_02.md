# Le Big Data
A quoi correspond techniquement cette r√©volution qu'on appelle commun√©ment "Big Data" et quelles sont ses cons√©quences sur l'analyse de donn√©es ?

## 1. Introduction
Tu viens de voir les deux familles d'outils indispensables √† la Data Analyse : les langages de programmation et les bases de donn√©es üëèüëè Il te reste √† voir encore deux familles d'outils : les outils d'analyse (que tu verras lors de la troisi√®me semaine de la formation) et les outils Big Data, qu'on va voir dans cette ressource. Les outils Big Data sont apparus r√©cemment et sont souvent g√©r√©s par des devs vue leur complexit√©. Mais il est important pour toi de comprendre leur utilit√© et leur fonctionnement.

## 2. Historique et contexte
On peut dater l‚Äôacte de naissance du big data en 2001 avec l‚Äôinvention de la r√®gle des 3V (Volume, Vitesse et Vari√©t√©). A l‚Äô√©poque, l‚Äôexpression traduisait une rupture dans le volume des donn√©es √† traiter. Jusqu‚Äô√† la fin des ann√©es 90, les quantit√©s de donn√©es restaient limit√©es. Puis, on a assist√© √† une explosion du volume de donn√©es avec l‚Äôessor de l‚Äôe-commerce, des r√©seaux sociaux, des terminaux mobiles et, plus r√©cemment, de l‚Äôinternet des objets (IoT). Face √† cette avalanche de data, les mod√®les techniques existants ont montr√© leurs limites. La base de donn√©es parfaite n‚Äôexistait plus. En fonction du souhait de privil√©gier la volum√©trie, la vitesse ou les capacit√©s de requ√™tage, on choisira une solution plut√¥t qu‚Äôune autre ou bien une combinaison d‚Äôoutils.

Pour leurs propres besoins, les GAFAM ont d√ª cr√©er des outils pour stocker et traiter √† la vol√©e des donn√©es √† la fois nombreuses et versatiles, leur structuration changeant avec le temps. Facebook est ainsi √† l‚Äôorigine de Cassandra avant de se tourner vers HBase (NoSQL), Google de BigTable et GFS (anc√™tre d‚ÄôHDFS) et plus r√©cemment de TensorFlow (machine learning). Les g√©ants du web ont ensuite vers√© ces projets en open source, externalisant en quelque sorte leur R&D. Car √† leurs yeux, l‚Äôor ce sont les donn√©es elles-m√™mes, pas les technologies. 
 
Finalement, apr√®s avoir √©t√© longtemps un buzzword, "Big Data" a repris son sens premier : il fait r√©f√©rence √† l'ensemble des technologies comme Hadoop, Spark, les bases de donn√©es NoSQL ... que tu vas d√©couvrir aujourd'hui.

## 3. La ressource

L'univers du Big Data est complexe et pourrait faire l'objet de plusieurs semaines de formation. Mais dans ton cas de futur Data Analyst, une journ√©e suffira car tu as surtout besoin d'avoir les bases pour pouvoir ensuite naviguer dans un projet Big Data. En fait, ce n'est pas toi qui devras cr√©er les infrastructures Big Data, c'est le r√¥le du *Data Engineer* ou *Data Architect*. On va donc te livrer ici les notions les plus importantes pour comprendre le Big Data.

https://matheo.uliege.be/bitstream/2268.2/2562/4/M%C3%A9moire%20Camille%20Marenne.pdf

https://inventiv-it.fr/big-data-devez-apprendre/

https://www.atys-concept.com/blog-de-la-performance/articles-performance-industrielle/differences-entre-data-analytics-data-science-big-data/

https://www.decideo.fr/Les-6-competences-les-plus-recherchees-en-Big-Data_a10051.html


### 3.1. Big data is not only big !

On pourrait penser que le Big Data (m√©gadonn√©es en fran√ßais) se r√©sume √† des gros volumes de donn√©es. Mais sans parler de Big Data, il est aujourd‚Äôhui possible de stocker et d‚Äôexploiter de tr√®s gros volumes de donn√©es avec une grande vari√©t√© de sources dans de grands entrep√¥ts de donn√©es (les *Data Warehouses*). En effet, les technologies actuelles permettent de traiter des gros volumes de donn√©es selon les m√©thodes analytiques de Business Intelligence sans avoir recours au Big Data (cf. la ressource pr√©c√©dente).

Si le Big Data concerne effectivement des gros volumes de donn√©es, une de ses sp√©cificit√©s est de s‚Äôint√©resser aussi bien aux donn√©es structur√©es qu‚Äôaux donn√©es non structur√©es. Ce sont les donn√©es non structur√©es que les outils habituels d‚Äôanalytique ne savent pas traiter. Une autre sp√©cificit√© est le stockage des donn√©es, qui ne sont plus stock√©es dans des *Data Warehouses* mais dans des *Data Lakes*. Finalement, plus que les volumes, ce qui fait le Big Data est donc la nature des donn√©es, la mani√®re dont on les stocke et les techniques d‚Äôanalyse pratiqu√©es avec des savoir-faire et des technologies propres.

En fait, au tout d√©but, on a parl√© des 3V : volume (grandes quantit√©s), vari√©t√© (diff√©rents types de donn√©es) et v√©locit√© (rapidit√© de traitement). Mais ce que l‚Äôacronyme des 3V ne mettait pas en perspective, c‚Äô√©tait cette innovation centrale qui veut que **les donn√©es n‚Äôont pas besoin d‚Äô√™tre syst√©matiquement ¬´ transform√©es ¬ª pour √™tre analys√©es**. Apparaissait donc une nouvelle approche, tr√®s diff√©rente de l'approche ETL o√π La donn√©e est structur√©e et convertie √† des formats pr√©cis. 

‚ö†Ô∏è‚ö†Ô∏è Ne croyez pas pour autant que les big data rendent les *data warehouses* obsol√®tes. Les syst√®mes de big data vous am√®nent √† travailler avec des donn√©es non structur√©es, mais le type de r√©sultats de requ√™tes que vous obtenez est loin de la sophistication des *data warehouses*. La *data warehouse* est con√ßue pour une analyse en profondeur de la donn√©e, et cela est rendu possible pr√©cis√©ment parce que la donn√©e a √©t√© transform√©e et pr√©vue dans un format sp√©cifique.

Le big data permet d‚Äôanalyser beaucoup plus de donn√©es de beaucoup plus de sources, mais avec une r√©solution moins fine. Pour sch√©matiser, on peut dire que le big data est un monde impressionniste qui aura toujours besoin √† ses c√¥t√©s de l‚Äôhyper-r√©alisme des *data warehouses* üé® C‚Äôest pour cela que nous sommes condamn√©s √† vivre √† la fois avec les *data warehouses* traditionnelles  et ce nouveau style de traitement que sont les big data. Le big data ne consiste donc surtout pas √† d√©sapprendre ce que l‚Äôon a appris en se formant au *data warehouse*. Le data scientist n‚Äôa pas forc√©ment vocation √† prendre la place de l‚Äôing√©nieur en informatique d√©cisionnelle. Il faudra au contraire que l‚Äôentreprise se pose la question de comment faire en sorte que les deux s‚Äôenrichissent mutuellement. Et c'est aussi ces deux aspects que nous allons t'apprendre dans cette formation.

___

üí°üí° AIDE MN√âMOTECHNIQUE üí°üí°

Pour synth√©tiser, le Big Data c'est une famille d'outils qui r√©pondent non pas √† 3 mais √† 5Vs √† la fois : 
- **Volume** -> des ensembles de donn√©es tr√®s volumineux 
- **Vitesse** ou **V√©locit√©** -> la vitesse √† laquelle les donn√©es sont g√©n√©r√©es et √† laquelle elles se d√©placent
- **Vari√©t√©** -> en fait, 80% des donn√©es dans le monde ne sont plus structur√©es et ne peuvent donc pas √™tre facilement mises dans des tables ou des bases de donn√©es relationnelles - pense √† des photos, des s√©quences vid√©os ou des mises √† jour de r√©seaux sociaux ‚åöÔ∏èüì±
- **V√©racit√©** -> les donn√©es sont devenues incertaines : il faut g√©rer la fiabilit√© de donn√©es intrins√®quement impr√©cises.
- **Valeur** -> finalement, tous ces volumes de donn√©es vari√©es en mouvement rapide et de v√©racit√© diff√©rente doivent √™tre transform√©s en valeur ! C'est l√† l'enjeu majeur du Big Data ‚öñÔ∏è‚öñÔ∏è

___


### 3.2. Les technos du Big Data

Trois grandes √©volutions techniques ont permis la cr√©ation et la croissance du Big Data :

- L‚Äô√©volution du hardware de stockage capable de stocker de plus en plus de donn√©es, passant de serveurs physiques internes √† l‚Äôentreprise √† des serveurs dit ‚Äúcloud‚Äù qui ont souvent une capacit√© de stockage bien sup√©rieure.
- Le second point est une remise en cause du mod√®le mat√©riel existant, celui o√π il fallait acheter le plus gros serveur possible. Aujourd‚Äôhui, la nouvelle √©volution consiste √† mettre en s√©rie des petits serveurs rempla√ßables et de cr√©er un syst√®me distribu√© r√©sistant aux pannes. Ce paradigme a √©t√© popularis√© par Google au d√©but des ann√©es 2000 et est √† l‚Äôorigine de la premi√®re version open source du premier framework Big Data sorti il y a 10 ans : Hadoop.
- La troisi√®me r√©volution s‚Äôest amorc√©e en 2009 et est l‚Äôexplosion des outils d‚Äôanalyse, d‚Äôextraction et de traitement des donn√©es de mani√®re non structur√©e que cela soit du NoSQL ou de nouveaux frameworks li√© √† l‚Äô√©cosyst√®me de Hadoop.

Les bases de donn√©es classiques ne permettant plus de g√©rer de tels volumes, les grands acteurs du web (Facebook, Google, Yahoo, Linkedin, Twitter) ont cr√©√© des Framework Big Data permettant de g√©rer et traiter des grandes quantit√©s de donn√©es √† travers, par exemple, des lacs de donn√©es. Ces donn√©es sont ensuite ‚Äúsplitt√©es‚Äù ou s√©par√©es pour √™tre trait√©es parall√®lement afin d‚Äôall√©ger les processus de calcul (dans l‚Äôancien mod√®le, les traitements √©taient fait les uns apr√®s les autres, dans un stack), puis r√©assembl√©es pour donner le r√©sultat final. C‚Äôest cette technologie qui permet des vitesses de traitement aussi rapides sur de gros volumes de donn√©es. Au d√©part d√©velopp√©e par Google, elle est maintenant sous le drapeau Apache et s‚Äôappelle Map Reduce.





#### 3.2.1 Mod√®le d'architecture







#### 3.2.1 MapReduce - algorithmes distribu√©s

Au d√©part, il y a eu **MapReduce**, une m√©thode et une technologie de traitement massivement parall√®le issues des laboratoires Google Corp  avec gestion de la tol√©rance aux pannes et syst√®me de gestion de fichiers sp√©cifiques (Google File System). On parle l√† de traitement sur des milliers de machines r√©parties en grappes (clusters). 

#### 3.2.2 Hadoop

#### 3.2.3 Spark 



#### 3.2.4 Le cloud computing

#### 3.2.5 Les bases de donn√©es NoSQL




## 4. Points importants √† retenir
Au-del√† des buzz words, l'analyse de donn√©es prend diff√©rentes formes et peut se r√©aliser √† diff√©rents niveaux. On peut distinguer deux types d'analyses : 
- l'analyse de donn√©es au travers de logiciels de *Business Intelligence* qui permet de faire parler les donn√©es, le plus souvent d√©j√† collect√©es et stock√©es dans l‚Äôentreprise.
- l‚Äôanalytique Big Data qui n√©cessite l‚Äôintervention de sp√©cialistes et la mise en ≈ìuvre d‚Äôune architecture informatique et d‚Äôoutils complexes. 


## 5. Pour aller plus loin


peut-√™tre mettre une blague ex : "si tu me crois pas qu'Hadoop est indispensable, cf https://www.decideo.fr/Les-6-competences-les-plus-recherchees-en-Big-Data_a10051.html"

# Le Big Data
A quoi correspond techniquement cette r√©volution qu'on appelle commun√©ment "Big Data" et quelles sont ses cons√©quences sur l'analyse de donn√©es ?

## 1. Introduction
Tu viens de voir les deux familles d'outils indispensables √† la Data Analyse : les langages de programmation et les bases de donn√©es üëèüëè Il te reste √† voir encore deux familles d'outils : les outils d'analyse (que tu verras lors de la troisi√®me semaine de la formation) et les outils Big Data, qu'on va voir dans cette ressource. Les outils Big Data sont apparus r√©cemment et sont souvent g√©r√©s par des devs vue leur complexit√©. Mais il est important pour toi de comprendre leur utilit√© et leur fonctionnement.

## 2. Historique et contexte
On peut dater l‚Äôacte de naissance du big data en 2001 avec l‚Äôinvention de la r√®gle des 3V (Volume, Vitesse et Vari√©t√©). A l‚Äô√©poque, l‚Äôexpression traduisait une rupture dans le volume des donn√©es √† traiter. Jusqu‚Äô√† la fin des ann√©es 90, les quantit√©s de donn√©es restaient limit√©es. Puis, on a assist√© √† une explosion du volume de donn√©es avec l‚Äôessor de l‚Äôe-commerce, des r√©seaux sociaux, des terminaux mobiles et, plus r√©cemment, de l‚Äôinternet des objets (IoT). Face √† cette avalanche de data, les mod√®les techniques existants ont montr√© leurs limites. La base de donn√©es parfaite n‚Äôexistait plus. En fonction du souhait de privil√©gier la volum√©trie, la vitesse ou les capacit√©s de requ√™tage, on choisira une solution plut√¥t qu‚Äôune autre ou bien une combinaison d‚Äôoutils.

Pour leurs propres besoins, les GAFAM ont d√ª cr√©er des outils pour stocker et traiter √† la vol√©e des donn√©es √† la fois nombreuses et versatiles, leur structuration changeant avec le temps. Facebook est ainsi √† l‚Äôorigine de Cassandra avant de se tourner vers HBase (NoSQL), Google de BigTable et GFS (anc√™tre d‚ÄôHDFS) et plus r√©cemment de TensorFlow (machine learning). Les g√©ants du web ont ensuite vers√© ces projets en open source, externalisant en quelque sorte leur R&D. Car √† leurs yeux, l‚Äôor ce sont les donn√©es elles-m√™mes, pas les technologies. 
 
Finalement, apr√®s avoir √©t√© longtemps un buzzword, "Big Data" a repris son sens premier : il fait r√©f√©rence √† l'ensemble des technologies comme Hadoop, Spark, Kafka ... que tu vas d√©couvrir aujourd'hui.

## 3. La ressource

L'univers du Big Data est complexe et pourrait faire l'objet de plusieurs semaines de formation. Mais dans ton cas de futur Data Analyst, une journ√©e suffira car tu as surtout besoin d'avoir les bases pour pouvoir ensuite naviguer dans un projet Big Data. En fait, ce n'est pas toi qui devras cr√©er les infrastructures Big Data, c'est le r√¥le du *Data Engineer* ou *Data Architect*. On va donc te livrer ici les notions les plus importantes pour comprendre le Big Data.

https://matheo.uliege.be/bitstream/2268.2/2562/4/M%C3%A9moire%20Camille%20Marenne.pdf

https://inventiv-it.fr/big-data-devez-apprendre/

https://www.atys-concept.com/blog-de-la-performance/articles-performance-industrielle/differences-entre-data-analytics-data-science-big-data/

https://www.decideo.fr/Les-6-competences-les-plus-recherchees-en-Big-Data_a10051.html


### 3.1. Big data is not only big !

On pourrait penser que le Big Data (m√©gadonn√©es en fran√ßais) se r√©sume √† des gros volumes de donn√©es. Mais sans parler de Big Data, il est aujourd‚Äôhui possible de stocker et d‚Äôexploiter de tr√®s gros volumes de donn√©es avec une grande vari√©t√© de sources dans de grands entrep√¥ts de donn√©es (les *Data Warehouses*). En effet, les technologies actuelles permettent de traiter des gros volumes de donn√©es selon les m√©thodes analytiques de Business Intelligence sans avoir recours au Big Data (cf. la ressource pr√©c√©dente).

Si le Big Data concerne effectivement des gros volumes de donn√©es, une de ses sp√©cificit√©s est de s‚Äôint√©resser aussi bien aux donn√©es structur√©es qu‚Äôaux donn√©es non structur√©es. Ce sont les donn√©es non structur√©es que les outils habituels d‚Äôanalytique ne savent pas traiter. Une autre sp√©cificit√© est le stockage des donn√©es, qui ne sont plus stock√©es dans des *Data Warehouses* mais dans des *Data Lakes*. Finalement, plus que les volumes, ce qui fait le Big Data est donc la nature des donn√©es, la mani√®re dont on les stocke et les techniques d‚Äôanalyse pratiqu√©es avec des savoir-faire et des technologies propres.

En fait, au tout d√©but, on a parl√© des 3V : volume (grandes quantit√©s), vari√©t√© (diff√©rents types de donn√©es) et v√©locit√© (rapidit√© de traitement). Mais ce que l‚Äôacronyme des 3V ne mettait pas en perspective, c‚Äô√©tait cette innovation centrale qui veut que **les donn√©es n‚Äôont pas besoin d‚Äô√™tre syst√©matiquement ¬´ transform√©es ¬ª pour √™tre analys√©es**. Apparaissait donc une nouvelle approche, tr√®s diff√©rente de l'approche ETL o√π La donn√©e est structur√©e et convertie √† des formats pr√©cis. 

‚ö†Ô∏è‚ö†Ô∏è Ne croyez pas pour autant que les big data rendent les *data warehouses* obsol√®tes. Les syst√®mes de big data vous am√®nent √† travailler avec des donn√©es non structur√©es, mais le type de r√©sultats de requ√™tes que vous obtenez est loin de la sophistication des *data warehouses*. La *data warehouse* est con√ßue pour une analyse en profondeur de la donn√©e, et cela est rendu possible pr√©cis√©ment parce que la donn√©e a √©t√© transform√©e et pr√©vue dans un format sp√©cifique.

Le big data permet d‚Äôanalyser beaucoup plus de donn√©es de beaucoup plus de sources, mais avec une r√©solution moins fine. Pour sch√©matiser, on peut dire que le big data est un monde impressionniste qui aura toujours besoin √† ses c√¥t√©s de l‚Äôhyper-r√©alisme des *data warehouses* üé® C‚Äôest pour cela que nous sommes condamn√©s √† vivre √† la fois avec les *data warehouses* traditionnelles  et ce nouveau style de traitement que sont les big data. Le big data ne consiste donc surtout pas √† d√©sapprendre ce que l‚Äôon a appris en se formant au *data warehouse*. Le data scientist n‚Äôa pas forc√©ment vocation √† prendre la place de l‚Äôing√©nieur en informatique d√©cisionnelle. Il faudra au contraire que l‚Äôentreprise se pose la question de comment faire en sorte que les deux s‚Äôenrichissent mutuellement. Et c'est aussi ces deux aspects que nous allons t'apprendre dans cette formation.

___

üí°üí° AIDE MN√âMOTECHNIQUE üí°üí°

Pour synth√©tiser, le Big Data c'est non pas 3 mais 5Vs √† la fois : 
- **Volume** -> des ensembles de donn√©es tr√®s volumineux 
- **Vitesse** ou **V√©locit√©** -> la vitesse √† laquelle les donn√©es sont g√©n√©r√©es et √† laquelle elles se d√©placent
- **Vari√©t√©** -> en fait, 80% des donn√©es dans le monde ne sont plus structur√©es et ne peuvent donc pas √™tre facilement mises dans des tables ou des bases de donn√©es relationnelles - pense √† des photos, des s√©quences vid√©os ou des mises √† jour de r√©seaux sociaux ‚åöÔ∏èüì±
- **V√©racit√©** -> les donn√©es sont devenues incertaines : il faut g√©rer la fiabilit√© de donn√©es intrins√®quement impr√©cises.
- **Valeur** -> finalement, tous ces volumes de donn√©es vari√©es en mouvement rapide et de v√©racit√© diff√©rente doivent √™tre transform√©s en valeur ! C'est l√† l'enjeu majeur du Big Data ‚öñÔ∏è‚öñÔ∏è

___


### 3.2. Les technos du Big Data

#### 3.2.1 Hadoop


#### 3.2.2 MapReduce

#### 3.2.3 Spark 

Google est √† l‚Äôorigine des deux perc√©es technologiques qui ont rendu les big data possibles :

Le premier √©tait Hadoop, qui consiste en deux services cl√©s :

    un syst√®me de stockage de donn√©es, utilisant HDFS (Hadoop Distributed File System)
    un syst√®me de process de donn√©es en parall√®le, utilisant une technique appel√©e Map Reduce.

Hadoop fonctionne sur un ensemble de serveurs en architecture shared-nothing. On peut ajouter ou enlever des serveurs √† volont√© dans un cluster Hadoop. Le syst√®me d√©tecte et r√®gle les probl√®me sur chaque serveur. Hadoop, en d‚Äôautres termes, ¬´ s‚Äôauto-gu√©rit ¬ª. Il peut donc continuer √† d√©livrer des donn√©es et fonctionner √† grande √©chelle en effectuant des t√¢ches exigeant de hautes performances, malgr√© des changements ou des √©checs.

Sa v√©ritable valeur ajout√©e est cependant encore ailleurs : elle provient de adds-on et de compl√©ments personnalisables de sa technologie. Hadoop offre ainsi des projets suppl√©mentaires qui ajoutent des fonctionnalit√©s √† la plateforme :

    Hadoop Common: il s‚Äôagit des outils de base n√©cessaires aux autres projets Hadoop
    Chukwa: un syst√®me de r√©cup√©ration de donn√©es pour g√©rer les syst√®mes distribu√©s de grande taille.
    HBase: une base de donn√©es distribu√©e, scalable qui supporte le stockage de donn√©es structur√©es pour de grandes tables.
    HDFS: un syst√®me distribu√© qui procure des acc√®s haut d√©bit aux donn√©es d‚Äôapplication
    Hive: une infrastructure de data warehouse qui d√©livre de la data summarization et un syst√®me de requ√™tes ad hoc.
    MapReduce: un framework logiciel pour les process distribu√©s de sets de donn√©es importants
    Pig: un langage et un framework permettant l‚Äôex√©cution de process parall√®les.
    ZooKeeper: un service de coordination haute performance pour les applications distribu√©es.

L‚Äôimpl√©mentation  d‚Äôune plateforme Hadoop comprend forc√©ment quelques un de ces sous-projets.

Par exemple, de nombreuses organisations choisissent d‚Äôutiliser HDFS comme syst√®me primaire de gestion de fichiers distribu√©s et HBase comme base de donn√©es qui peut stocker des milliards de colonnes de donn√©es. Et le recours √† MapReduce (ou Spark) va s‚Äôimposer ensuite presque de soi puisqu‚Äôil apporte la vitesse et l‚Äôagilit√© √† la plateforme Hadoop.

Avec MapReduce, les d√©veloppeurs peuvent cr√©er des programmes qui traitent des volumes massifs de donn√©es non structur√©es en parall√®le √† travers un cluster de processeurs distribu√©s sur des ordinateurs ind√©pendants. Le framework MapReduce est scind√© en deux espaces fonctionnels :

    Map, une fonction qui r√©partit le travail √† diff√©rents noeuds dans les grappes d‚Äôordinateurs.
    Reduce, une fonction qui rassemble le travail et r√©sume les r√©sultats dans une valeur simple.

Un des avantages primaires de Map Reduce est qu‚Äôil est ¬´ fault-tolerant ¬ª ou tol√©rant aux pannes. Comment fait-il ? Il ¬´ monitore ¬ª chaque noeud (node) du cluster r√©guli√®rement. Celui-ci est suppos√© renvoyer p√©riodiquement un travail complet avec des mises √† jour des ¬´ status ¬ª. Si un noeud reste silencieux plus que n√©cessaire, un master node le signale et r√©assigne le travail √† d‚Äôautres noeuds du cluster.

Construit √† l‚Äôorigine pour ind√©xer le moteur de recherche Nutch, Hadoop est maintenant utilis√© dans tous les grands secteurs d‚Äôactivit√© pour quantit√© de t√¢ches big data.

En d‚Äôautres termes, gr√¢ce au syst√®me d‚Äôinformatique distribu√©e HDFS et YARN (Yet Another Resource Negotiator), le logiciel permet √† l‚Äôutilisateur de traiter des volumes de donn√©es gigantesques r√©partis √† travers des milliers d‚Äôordinateurs, exactement comme s‚Äôils √©taient une seule et m√™me √©norme machine.

Comment adapter cela √† votre cas ? L‚Äôhistoire de ces sauts technologiques s‚Äôimpose forc√©ment √† votre organisation et √† vous-m√™me. L‚Äôinformatique distribu√©e ne vous est pas suffisamment famili√®re ? Il est urgent de mieux la comprendre et de vous y former, vous ou vos √©quipes. 

Quant aux outils, l‚Äôhistoire d‚ÄôHadoop montre √† quel point sa logique s‚Äôimpose √† l‚Äôunivers Big Data. Son univers ne doit donc pas vous rester √©tranger. Songez-y. Mais l‚Äôhistoire n‚Äôest pas finie. 

En 2009, des cherchers de l‚ÄôUniversit√© de Californie √† Berkeley ont d√©velopp√© Apache Spark , une alternative √† MapReduce. Spark proc√®de √† ses calculs en parall√®le en utilisant du stokage in-memory, il est jusqu‚Äô√† 100 fois plus rapide que MapReduce. Spark peut √™tre utilis√© seul ou √† l‚Äôint√©rieur d‚ÄôHadoop.

M√™me avec Hadoop, il faut quand m√™me un moyen de stocker et d‚Äôacc√©der aux donn√©es. C‚Äôest typiquement ce √† quoi servent des NoSQL database telles que Mongo DB, CouchDG ou Cassandra, sp√©cialis√©es dans le traitement des donn√©es non-structur√©es ou semi-structur√©es et distribu√©es √† travers de multiples machines.

A la diff√©rence de ce qui se passe dans les data warehouses, o√π des quantit√©s massives de donn√©es sont envoy√©es vers un format unifi√© et sont stock√©es dans un data store unique, ces outils ne changent pas la nature ni la localisation de la donn√©e d‚Äôorigine ‚Äì les emails restent des emails, les donn√©es de capteurs restent des donn√©es de capteurs- et peuvent √™tre stock√©s virtuellement n‚Äôimporte o√π.

Reste un probl√®me : disposer de quantit√©s massives de donn√©es dans des bases NoSQL install√©es dans des clusters de machines n‚Äôest pas tr√®s utile tant que vous n‚Äôen faites rien.
C‚Äôest l√† qu‚Äôinterviennent les analytics de big data.

Des outils tels que  Tableau, Splunk, et Jasper BI permettent de parser ces data pour identifier des patterns, extraire des significations et r√©v√©ler de nouvelles perspectives. Ce que vous en ferez ensuite d√©pendra de vos besoins.

L√† encore, les comp√©tences dans ces analytics sont particuli√®rement demand√©es. Cela fait partie des comp√©tences √† acqu√©rir. Noter √©galement que la ma√Ætrise des bases NoSQL semble importante, voire indispensable. Conna√Ætre et ma√Ætriser le NoSQL semble donc √† ce jour indispensable √† l‚Äôunivers big data. Quoique‚Ä¶dans cet article, vous verrez que SQL revient en force dans l‚Äôunivers big data. 


## 4. Points importants √† retenir
Au-del√† des buzz words, l'analyse de donn√©es prend diff√©rentes formes et peut se r√©aliser √† diff√©rents niveaux. On peut distinguer deux types d'analyses : 
- l'analyse de donn√©es au travers de logiciels de *Business Intelligence* qui permet de faire parler les donn√©es, le plus souvent d√©j√† collect√©es et stock√©es dans l‚Äôentreprise.
- l‚Äôanalytique Big Data qui n√©cessite l‚Äôintervention de sp√©cialistes et la mise en ≈ìuvre d‚Äôune architecture informatique et d‚Äôoutils complexes. 


## 5. Pour aller plus loin


peut-√™tre mettre une blague ex : "si tu me crois pas qu'Hadoop est indispensable, cf https://www.decideo.fr/Les-6-competences-les-plus-recherchees-en-Big-Data_a10051.html"

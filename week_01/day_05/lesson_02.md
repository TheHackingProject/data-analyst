# Le Big Data
A quoi correspond techniquement cette rÃ©volution qu'on appelle communÃ©ment "Big Data" et quelles sont ses consÃ©quences sur l'analyse de donnÃ©es ?

## 1. Introduction
Tu viens de voir les deux familles d'outils indispensables Ã  la Data Analyse : les langages de programmation et les bases de donnÃ©es ğŸ‘ğŸ‘ Il te reste Ã  voir encore deux familles d'outils : les outils d'analyse (que tu verras lors de la troisiÃ¨me semaine de la formation) et les outils Big Data, qu'on va voir dans cette ressource. Les outils Big Data sont apparus rÃ©cemment et sont souvent gÃ©rÃ©s par des devs vue leur complexitÃ©. Mais il est important pour toi de comprendre leur utilitÃ© et leur fonctionnement.

## 2. Historique et contexte
On peut dater lâ€™acte de naissance du big data en 2001 avec lâ€™invention de la rÃ¨gle des 3V (Volume, Vitesse et VariÃ©tÃ©). A lâ€™Ã©poque, lâ€™expression traduisait une rupture dans le volume des donnÃ©es Ã  traiter. Jusquâ€™Ã  la fin des annÃ©es 90, les quantitÃ©s de donnÃ©es restaient limitÃ©es. Puis, on a assistÃ© Ã  une explosion du volume de donnÃ©es avec lâ€™essor de lâ€™e-commerce, des rÃ©seaux sociaux, des terminaux mobiles et, plus rÃ©cemment, de lâ€™internet des objets (IoT). Face Ã  cette avalanche de data, les modÃ¨les techniques existants ont montrÃ© leurs limites. La base de donnÃ©es parfaite nâ€™existait plus. En fonction du souhait de privilÃ©gier la volumÃ©trie, la vitesse ou les capacitÃ©s de requÃªtage, on choisira une solution plutÃ´t quâ€™une autre ou bien une combinaison dâ€™outils.

Pour leurs propres besoins, les GAFAM ont dÃ» crÃ©er des outils pour stocker et traiter Ã  la volÃ©e des donnÃ©es Ã  la fois nombreuses et versatiles, leur structuration changeant avec le temps. Facebook est ainsi Ã  lâ€™origine de Cassandra avant de se tourner vers HBase (NoSQL), Google de BigTable et GFS (ancÃªtre dâ€™HDFS) et plus rÃ©cemment de TensorFlow (machine learning). Les gÃ©ants du web ont ensuite versÃ© ces projets en open source, externalisant en quelque sorte leur R&D. Car Ã  leurs yeux, lâ€™or ce sont les donnÃ©es elles-mÃªmes, pas les technologies. 
 
Finalement, aprÃ¨s avoir Ã©tÃ© longtemps un buzzword, "Big Data" a repris son sens premier : il fait rÃ©fÃ©rence Ã  l'ensemble des technologies comme Hadoop, Spark, Kafka ... que tu vas dÃ©couvrir aujourd'hui.

## 3. La ressource

L'univers du Big Data est complexe et pourrait faire l'objet de plusieurs semaines de formation. Mais dans ton cas de futur Data Analyst, une journÃ©e suffira car tu as surtout besoin d'avoir les bases pour pouvoir ensuite naviguer dans un projet Big Data. En fait, ce n'est pas toi qui devras crÃ©er les infrastructures Big Data, c'est le rÃ´le du *Data Engineer* ou *Data Architect*. On va donc te livrer ici les notions les plus importantes pour comprendre le Big Data.

https://matheo.uliege.be/bitstream/2268.2/2562/4/M%C3%A9moire%20Camille%20Marenne.pdf

https://inventiv-it.fr/big-data-devez-apprendre/

https://www.atys-concept.com/blog-de-la-performance/articles-performance-industrielle/differences-entre-data-analytics-data-science-big-data/

https://www.decideo.fr/Les-6-competences-les-plus-recherchees-en-Big-Data_a10051.html


### 3.1. Big data is not only big !

On pourrait penser que le Big Data (mÃ©gadonnÃ©es en franÃ§ais) se rÃ©sume Ã  des gros volumes de donnÃ©es. Mais sans parler de Big Data, il est aujourdâ€™hui possible de stocker et dâ€™exploiter de trÃ¨s gros volumes de donnÃ©es avec une grande variÃ©tÃ© de sources dans de grands entrepÃ´ts de donnÃ©es (les *Data Warehouses*). En effet, les technologies actuelles permettent de traiter des gros volumes de donnÃ©es selon les mÃ©thodes analytiques de Business Intelligence sans avoir recours au Big Data (cf. la ressource prÃ©cÃ©dente).

Si le Big Data concerne effectivement des gros volumes de donnÃ©es, une de ses spÃ©cificitÃ©s est de sâ€™intÃ©resser aussi bien aux donnÃ©es structurÃ©es quâ€™aux donnÃ©es non structurÃ©es. Ce sont les donnÃ©es non structurÃ©es que les outils habituels dâ€™analytique ne savent pas traiter. Une autre spÃ©cificitÃ© est le stockage des donnÃ©es, qui ne sont plus stockÃ©es dans des *Data Warehouses* mais dans des *Data Lakes*. Finalement, plus que les volumes, ce qui fait le Big Data est donc la nature des donnÃ©es, la maniÃ¨re dont on les stocke et les techniques dâ€™analyse pratiquÃ©es avec des savoir-faire et des technologies propres.

En fait, au tout dÃ©but, on a parlÃ© des 3V : volume (grandes quantitÃ©s), variÃ©tÃ© (diffÃ©rents types de donnÃ©es) et vÃ©locitÃ© (rapiditÃ© de traitement). Mais ce que lâ€™acronyme des 3V ne mettait pas en perspective, câ€™Ã©tait cette innovation centrale qui veut que **les donnÃ©es nâ€™ont pas besoin dâ€™Ãªtre systÃ©matiquement Â« transformÃ©es Â» pour Ãªtre analysÃ©es**. Apparaissait donc une nouvelle approche, trÃ¨s diffÃ©rente de l'approche ETL oÃ¹ La donnÃ©e est structurÃ©e et convertie Ã  des formats prÃ©cis. 

âš ï¸âš ï¸ Ne croyez pas pour autant que les big data rendent les *data warehouses* obsolÃ¨tes. Les systÃ¨mes de big data vous amÃ¨nent Ã  travailler avec des donnÃ©es non structurÃ©es, mais le type de rÃ©sultats de requÃªtes que vous obtenez est loin de la sophistication des *data warehouses*. La *data warehouse* est conÃ§ue pour une analyse en profondeur de la donnÃ©e, et cela est rendu possible prÃ©cisÃ©ment parce que la donnÃ©e a Ã©tÃ© transformÃ©e et prÃ©vue dans un format spÃ©cifique.

Le big data permet dâ€™analyser beaucoup plus de donnÃ©es de beaucoup plus de sources, mais avec une rÃ©solution moins fine. Pour schÃ©matiser, on peut dire que le big data est un monde impressionniste qui aura toujours besoin Ã  ses cÃ´tÃ©s de lâ€™hyper-rÃ©alisme des *data warehouses* ğŸ¨ Câ€™est pour cela que nous sommes condamnÃ©s Ã  vivre Ã  la fois avec les *data warehouses* traditionnelles  et ce nouveau style de traitement que sont les big data. Le big data ne consiste donc surtout pas Ã  dÃ©sapprendre ce que lâ€™on a appris en se formant au *data warehouse*. Le data scientist nâ€™a pas forcÃ©ment vocation Ã  prendre la place de lâ€™ingÃ©nieur en informatique dÃ©cisionnelle. Il faudra au contraire que lâ€™entreprise se pose la question de comment faire en sorte que les deux sâ€™enrichissent mutuellement. Et c'est aussi ces deux aspects que nous allons t'apprendre dans cette formation.

___

ğŸ’¡ğŸ’¡ AIDE MNÃ‰MOTECHNIQUE ğŸ’¡ğŸ’¡

Pour synthÃ©tiser, le Big Data c'est non pas 3 mais 5Vs Ã  la fois : 
- **Volume** -> des ensembles de donnÃ©es trÃ¨s volumineux 
- **Vitesse** ou **VÃ©locitÃ©** -> la vitesse Ã  laquelle les donnÃ©es sont gÃ©nÃ©rÃ©es et Ã  laquelle elles se dÃ©placent
- **VariÃ©tÃ©** -> en fait, 80% des donnÃ©es dans le monde ne sont plus structurÃ©es et ne peuvent donc pas Ãªtre facilement mises dans des tables ou des bases de donnÃ©es relationnelles - pense Ã  des photos, des sÃ©quences vidÃ©os ou des mises Ã  jour de rÃ©seaux sociaux âŒšï¸ğŸ“±
- **VÃ©racitÃ©** -> les donnÃ©es sont devenues incertaines : il faut gÃ©rer la fiabilitÃ© de donnÃ©es intrinsÃ¨quement imprÃ©cises.
- **Valeur** -> finalement, tous ces volumes de donnÃ©es variÃ©es en mouvement rapide et de vÃ©racitÃ© diffÃ©rente doivent Ãªtre transformÃ©s en valeur ! C'est lÃ  l'enjeu majeur du Big Data âš–ï¸âš–ï¸

___


### 3.2. Les technos du Big Data

#### 3.2.1 Hadoop


#### 3.2.2 MapReduce

#### 3.2.3 Spark 

Google est Ã  lâ€™origine des deux percÃ©es technologiques qui ont rendu les big data possibles :

Le premier Ã©tait Hadoop, qui consiste en deux services clÃ©s :

    un systÃ¨me de stockage de donnÃ©es, utilisant HDFS (Hadoop Distributed File System)
    un systÃ¨me de process de donnÃ©es en parallÃ¨le, utilisant une technique appelÃ©e Map Reduce.

Hadoop fonctionne sur un ensemble de serveurs en architecture shared-nothing. On peut ajouter ou enlever des serveurs Ã  volontÃ© dans un cluster Hadoop. Le systÃ¨me dÃ©tecte et rÃ¨gle les problÃ¨me sur chaque serveur. Hadoop, en dâ€™autres termes, Â« sâ€™auto-guÃ©rit Â». Il peut donc continuer Ã  dÃ©livrer des donnÃ©es et fonctionner Ã  grande Ã©chelle en effectuant des tÃ¢ches exigeant de hautes performances, malgrÃ© des changements ou des Ã©checs.

Sa vÃ©ritable valeur ajoutÃ©e est cependant encore ailleurs : elle provient de adds-on et de complÃ©ments personnalisables de sa technologie. Hadoop offre ainsi des projets supplÃ©mentaires qui ajoutent des fonctionnalitÃ©s Ã  la plateforme :

    Hadoop Common: il sâ€™agit des outils de base nÃ©cessaires aux autres projets Hadoop
    Chukwa: un systÃ¨me de rÃ©cupÃ©ration de donnÃ©es pour gÃ©rer les systÃ¨mes distribuÃ©s de grande taille.
    HBase: une base de donnÃ©es distribuÃ©e, scalable qui supporte le stockage de donnÃ©es structurÃ©es pour de grandes tables.
    HDFS: un systÃ¨me distribuÃ© qui procure des accÃ¨s haut dÃ©bit aux donnÃ©es dâ€™application
    Hive: une infrastructure de data warehouse qui dÃ©livre de la data summarization et un systÃ¨me de requÃªtes ad hoc.
    MapReduce: un framework logiciel pour les process distribuÃ©s de sets de donnÃ©es importants
    Pig: un langage et un framework permettant lâ€™exÃ©cution de process parallÃ¨les.
    ZooKeeper: un service de coordination haute performance pour les applications distribuÃ©es.

Lâ€™implÃ©mentation  dâ€™une plateforme Hadoop comprend forcÃ©ment quelques un de ces sous-projets.

Par exemple, de nombreuses organisations choisissent dâ€™utiliser HDFS comme systÃ¨me primaire de gestion de fichiers distribuÃ©s et HBase comme base de donnÃ©es qui peut stocker des milliards de colonnes de donnÃ©es. Et le recours Ã  MapReduce (ou Spark) va sâ€™imposer ensuite presque de soi puisquâ€™il apporte la vitesse et lâ€™agilitÃ© Ã  la plateforme Hadoop.

Avec MapReduce, les dÃ©veloppeurs peuvent crÃ©er des programmes qui traitent des volumes massifs de donnÃ©es non structurÃ©es en parallÃ¨le Ã  travers un cluster de processeurs distribuÃ©s sur des ordinateurs indÃ©pendants. Le framework MapReduce est scindÃ© en deux espaces fonctionnels :

    Map, une fonction qui rÃ©partit le travail Ã  diffÃ©rents noeuds dans les grappes dâ€™ordinateurs.
    Reduce, une fonction qui rassemble le travail et rÃ©sume les rÃ©sultats dans une valeur simple.

Un des avantages primaires de Map Reduce est quâ€™il est Â« fault-tolerant Â» ou tolÃ©rant aux pannes. Comment fait-il ? Il Â« monitore Â» chaque noeud (node) du cluster rÃ©guliÃ¨rement. Celui-ci est supposÃ© renvoyer pÃ©riodiquement un travail complet avec des mises Ã  jour des Â« status Â». Si un noeud reste silencieux plus que nÃ©cessaire, un master node le signale et rÃ©assigne le travail Ã  dâ€™autres noeuds du cluster.

Construit Ã  lâ€™origine pour indÃ©xer le moteur de recherche Nutch, Hadoop est maintenant utilisÃ© dans tous les grands secteurs dâ€™activitÃ© pour quantitÃ© de tÃ¢ches big data.

En dâ€™autres termes, grÃ¢ce au systÃ¨me dâ€™informatique distribuÃ©e HDFS et YARN (Yet Another Resource Negotiator), le logiciel permet Ã  lâ€™utilisateur de traiter des volumes de donnÃ©es gigantesques rÃ©partis Ã  travers des milliers dâ€™ordinateurs, exactement comme sâ€™ils Ã©taient une seule et mÃªme Ã©norme machine.

Comment adapter cela Ã  votre cas ? Lâ€™histoire de ces sauts technologiques sâ€™impose forcÃ©ment Ã  votre organisation et Ã  vous-mÃªme. Lâ€™informatique distribuÃ©e ne vous est pas suffisamment familiÃ¨re ? Il est urgent de mieux la comprendre et de vous y former, vous ou vos Ã©quipes. 

Quant aux outils, lâ€™histoire dâ€™Hadoop montre Ã  quel point sa logique sâ€™impose Ã  lâ€™univers Big Data. Son univers ne doit donc pas vous rester Ã©tranger. Songez-y. Mais lâ€™histoire nâ€™est pas finie. 

En 2009, des cherchers de lâ€™UniversitÃ© de Californie Ã  Berkeley ont dÃ©veloppÃ© Apache Spark , une alternative Ã  MapReduce. Spark procÃ¨de Ã  ses calculs en parallÃ¨le en utilisant du stokage in-memory, il est jusquâ€™Ã  100 fois plus rapide que MapReduce. Spark peut Ãªtre utilisÃ© seul ou Ã  lâ€™intÃ©rieur dâ€™Hadoop.

MÃªme avec Hadoop, il faut quand mÃªme un moyen de stocker et dâ€™accÃ©der aux donnÃ©es. Câ€™est typiquement ce Ã  quoi servent des NoSQL database telles que Mongo DB, CouchDG ou Cassandra, spÃ©cialisÃ©es dans le traitement des donnÃ©es non-structurÃ©es ou semi-structurÃ©es et distribuÃ©es Ã  travers de multiples machines.

A la diffÃ©rence de ce qui se passe dans les data warehouses, oÃ¹ des quantitÃ©s massives de donnÃ©es sont envoyÃ©es vers un format unifiÃ© et sont stockÃ©es dans un data store unique, ces outils ne changent pas la nature ni la localisation de la donnÃ©e dâ€™origine â€“ les emails restent des emails, les donnÃ©es de capteurs restent des donnÃ©es de capteurs- et peuvent Ãªtre stockÃ©s virtuellement nâ€™importe oÃ¹.

Reste un problÃ¨me : disposer de quantitÃ©s massives de donnÃ©es dans des bases NoSQL installÃ©es dans des clusters de machines nâ€™est pas trÃ¨s utile tant que vous nâ€™en faites rien.
Câ€™est lÃ  quâ€™interviennent les analytics de big data.

Des outils tels que  Tableau, Splunk, et Jasper BI permettent de parser ces data pour identifier des patterns, extraire des significations et rÃ©vÃ©ler de nouvelles perspectives. Ce que vous en ferez ensuite dÃ©pendra de vos besoins.

LÃ  encore, les compÃ©tences dans ces analytics sont particuliÃ¨rement demandÃ©es. Cela fait partie des compÃ©tences Ã  acquÃ©rir. Noter Ã©galement que la maÃ®trise des bases NoSQL semble importante, voire indispensable. ConnaÃ®tre et maÃ®triser le NoSQL semble donc Ã  ce jour indispensable Ã  lâ€™univers big data. Quoiqueâ€¦dans cet article, vous verrez que SQL revient en force dans lâ€™univers big data. 


## 4. Points importants Ã  retenir
Au-delÃ  des buzz words, l'analyse de donnÃ©es prend diffÃ©rentes formes et peut se rÃ©aliser Ã  diffÃ©rents niveaux. On peut distinguer deux types d'analyses : 
- l'analyse de donnÃ©es au travers de logiciels de *Business Intelligence* qui permet de faire parler les donnÃ©es, le plus souvent dÃ©jÃ  collectÃ©es et stockÃ©es dans lâ€™entreprise.
- lâ€™analytique Big Data qui nÃ©cessite lâ€™intervention de spÃ©cialistes et la mise en Å“uvre dâ€™une architecture informatique et dâ€™outils complexes. 


## 5. Pour aller plus loin


peut-Ãªtre mettre une blague ex : "si tu me crois pas qu'Hadoop est indispensable, cf https://www.decideo.fr/Les-6-competences-les-plus-recherchees-en-Big-Data_a10051.html"

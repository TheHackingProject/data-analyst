# Le Big Data
A quoi correspond techniquement cette rÃ©volution qu'on appelle communÃ©ment "Big Data" et quelles sont ses consÃ©quences sur l'analyse de donnÃ©es ?

## 1. Introduction
Tu viens de voir les deux familles d'outils indispensables Ã  la Data Analyse : les langages de programmation et les bases de donnÃ©es ğŸ‘ğŸ‘ Il te reste Ã  voir encore deux familles d'outils : les outils d'analyse (que tu verras lors de la troisiÃ¨me semaine de la formation) et les outils Big Data, qu'on va voir dans cette ressource. Les outils Big Data sont apparus rÃ©cemment et sont souvent gÃ©rÃ©s par des devs vue leur complexitÃ©. Mais il est important pour toi de comprendre leur utilitÃ© et leur fonctionnement.

## 2. Historique et contexte
On peut dater lâ€™acte de naissance du big data en 2001 avec lâ€™invention de la rÃ¨gle des 3V (Volume, Vitesse et VariÃ©tÃ©). A lâ€™Ã©poque, lâ€™expression traduisait une rupture dans le volume des donnÃ©es Ã  traiter. Jusquâ€™Ã  la fin des annÃ©es 90, les quantitÃ©s de donnÃ©es restaient limitÃ©es. Puis, on a assistÃ© Ã  une explosion du volume de donnÃ©es avec lâ€™essor de lâ€™e-commerce, des rÃ©seaux sociaux, des terminaux mobiles et, plus rÃ©cemment, de lâ€™internet des objets (IoT). Face Ã  cette avalanche de data, les modÃ¨les techniques existants ont montrÃ© leurs limites. La base de donnÃ©es parfaite nâ€™existait plus. En fonction du souhait de privilÃ©gier la volumÃ©trie, la vitesse ou les capacitÃ©s de requÃªtage, on choisira une solution plutÃ´t quâ€™une autre ou bien une combinaison dâ€™outils.

Pour leurs propres besoins, les GAFAM ont dÃ» crÃ©er des outils pour stocker et traiter Ã  la volÃ©e des donnÃ©es Ã  la fois nombreuses et versatiles, leur structuration changeant avec le temps. Facebook est ainsi Ã  lâ€™origine de Cassandra avant de se tourner vers HBase (NoSQL), Google de BigTable et GFS (ancÃªtre dâ€™HDFS) et plus rÃ©cemment de TensorFlow (machine learning). Les gÃ©ants du web ont ensuite versÃ© ces projets en open source, externalisant en quelque sorte leur R&D. Car Ã  leurs yeux, lâ€™or ce sont les donnÃ©es elles-mÃªmes, pas les technologies. 
 
Finalement, aprÃ¨s avoir Ã©tÃ© longtemps un buzzword, "Big Data" a repris son sens premier : il fait rÃ©fÃ©rence Ã  l'ensemble des technologies comme Hadoop, Spark, les bases de donnÃ©es NoSQL ... que tu vas dÃ©couvrir aujourd'hui.

## 3. La ressource

L'univers du Big Data est complexe et pourrait faire l'objet de plusieurs semaines de formation. Mais dans ton cas de futur Data Analyst, une journÃ©e suffira car tu as surtout besoin d'avoir les bases pour pouvoir ensuite naviguer dans un projet Big Data. En fait, ce n'est pas toi qui devras crÃ©er les infrastructures Big Data, c'est le rÃ´le du *Data Engineer* ou *Data Architect*. On va donc te livrer ici les notions les plus importantes pour comprendre le Big Data.

https://matheo.uliege.be/bitstream/2268.2/2562/4/M%C3%A9moire%20Camille%20Marenne.pdf

https://inventiv-it.fr/big-data-devez-apprendre/

https://www.atys-concept.com/blog-de-la-performance/articles-performance-industrielle/differences-entre-data-analytics-data-science-big-data/

https://www.decideo.fr/Les-6-competences-les-plus-recherchees-en-Big-Data_a10051.html


### 3.1. Big data is not only big !

On pourrait penser que le Big Data (mÃ©gadonnÃ©es en franÃ§ais) se rÃ©sume Ã  des gros volumes de donnÃ©es. Mais sans parler de Big Data, il est aujourdâ€™hui possible de stocker et dâ€™exploiter de trÃ¨s gros volumes de donnÃ©es avec une grande variÃ©tÃ© de sources dans de grands entrepÃ´ts de donnÃ©es (les *Data Warehouses*). En effet, les technologies actuelles permettent de traiter des gros volumes de donnÃ©es selon les mÃ©thodes analytiques de Business Intelligence sans avoir recours au Big Data (cf. la ressource prÃ©cÃ©dente).

Si le Big Data concerne effectivement des gros volumes de donnÃ©es, une de ses spÃ©cificitÃ©s est de sâ€™intÃ©resser aussi bien aux donnÃ©es structurÃ©es quâ€™aux donnÃ©es non structurÃ©es. Ce sont les donnÃ©es non structurÃ©es que les outils habituels dâ€™analytique ne savent pas traiter. Une autre spÃ©cificitÃ© est le stockage des donnÃ©es, qui ne sont plus stockÃ©es dans des *Data Warehouses* mais dans des *Data Lakes*. Finalement, plus que les volumes, ce qui fait le Big Data est donc la nature des donnÃ©es, la maniÃ¨re dont on les stocke et les techniques dâ€™analyse pratiquÃ©es avec des savoir-faire et des technologies propres.

En fait, au tout dÃ©but, on a parlÃ© des 3V : volume (grandes quantitÃ©s), variÃ©tÃ© (diffÃ©rents types de donnÃ©es) et vÃ©locitÃ© (rapiditÃ© de traitement). Mais ce que lâ€™acronyme des 3V ne mettait pas en perspective, câ€™Ã©tait cette innovation centrale qui veut que **les donnÃ©es nâ€™ont pas besoin dâ€™Ãªtre systÃ©matiquement Â« transformÃ©es Â» pour Ãªtre analysÃ©es**. Apparaissait donc une nouvelle approche, trÃ¨s diffÃ©rente de l'approche ETL oÃ¹ La donnÃ©e est structurÃ©e et convertie Ã  des formats prÃ©cis. 

âš ï¸âš ï¸ Ne croyez pas pour autant que les big data rendent les *data warehouses* obsolÃ¨tes. Les systÃ¨mes de big data vous amÃ¨nent Ã  travailler avec des donnÃ©es non structurÃ©es, mais le type de rÃ©sultats de requÃªtes que vous obtenez est loin de la sophistication des *data warehouses*. La *data warehouse* est conÃ§ue pour une analyse en profondeur de la donnÃ©e, et cela est rendu possible prÃ©cisÃ©ment parce que la donnÃ©e a Ã©tÃ© transformÃ©e et prÃ©vue dans un format spÃ©cifique.

Le big data permet dâ€™analyser beaucoup plus de donnÃ©es de beaucoup plus de sources, mais avec une rÃ©solution moins fine. Pour schÃ©matiser, on peut dire que le big data est un monde impressionniste qui aura toujours besoin Ã  ses cÃ´tÃ©s de lâ€™hyper-rÃ©alisme des *data warehouses* ğŸ¨ Câ€™est pour cela que nous sommes condamnÃ©s Ã  vivre Ã  la fois avec les *data warehouses* traditionnelles  et ce nouveau style de traitement que sont les big data. Le big data ne consiste donc surtout pas Ã  dÃ©sapprendre ce que lâ€™on a appris en se formant au *data warehouse*. Le data scientist nâ€™a pas forcÃ©ment vocation Ã  prendre la place de lâ€™ingÃ©nieur en informatique dÃ©cisionnelle. Il faudra au contraire que lâ€™entreprise se pose la question de comment faire en sorte que les deux sâ€™enrichissent mutuellement. Et c'est aussi ces deux aspects que nous allons t'apprendre dans cette formation.

___

ğŸ’¡ğŸ’¡ AIDE MNÃ‰MOTECHNIQUE ğŸ’¡ğŸ’¡

Pour synthÃ©tiser, le Big Data c'est une famille d'outils qui rÃ©pondent non pas Ã  3 mais Ã  5Vs Ã  la fois : 
- **Volume** -> des ensembles de donnÃ©es trÃ¨s volumineux 
- **Vitesse** ou **VÃ©locitÃ©** -> la vitesse Ã  laquelle les donnÃ©es sont gÃ©nÃ©rÃ©es et Ã  laquelle elles se dÃ©placent
- **VariÃ©tÃ©** -> en fait, 80% des donnÃ©es dans le monde ne sont plus structurÃ©es et ne peuvent donc pas Ãªtre facilement mises dans des tables ou des bases de donnÃ©es relationnelles - pense Ã  des photos, des sÃ©quences vidÃ©os ou des mises Ã  jour de rÃ©seaux sociaux âŒšï¸ğŸ“±
- **VÃ©racitÃ©** -> les donnÃ©es sont devenues incertaines : il faut gÃ©rer la fiabilitÃ© de donnÃ©es intrinsÃ¨quement imprÃ©cises.
- **Valeur** -> finalement, tous ces volumes de donnÃ©es variÃ©es en mouvement rapide et de vÃ©racitÃ© diffÃ©rente doivent Ãªtre transformÃ©s en valeur ! C'est lÃ  l'enjeu majeur du Big Data âš–ï¸âš–ï¸

___


### 3.2. Les technos du Big Data

Quatre grandes rÃ©volutions techniques ont permis la crÃ©ation et la croissance du Big Data :

- **Lâ€™Ã©volution du hardware de stockage**, passant de serveurs physiques internes Ã  lâ€™entreprise Ã  **des serveurs dits â€œcloudâ€** qui ont souvent une capacitÃ© de stockage bien supÃ©rieure. Au dÃ©but des annÃ©es 2000, sont apparus des hÃ©bergeurs web capables d'hÃ©berger des applications dans leurs locaux informatiques. 

- **De nouvelles techniques de calcul**.

- **Un nouveau modÃ¨le d'architecture**. Ce paradigme a Ã©tÃ© popularisÃ© par Google au dÃ©but des annÃ©es 2000 et est Ã  lâ€™origine de la premiÃ¨re version open source du premier framework Big Data : Hadoop.

- **Un nouveau type de bases de donnÃ©es : le NoSQL**. 

#### 3.2.1 Le cloud computing

Avant lâ€™arrivÃ©e des plateformes informatiques cloud, le stockage et lâ€™utilisation du Big Data Ã©taient effectuÃ©s sur site. Lâ€™introduction des plateformes en cloud computing comme Microsoft Azure, Amazon AWS ou Google BigQuery permet dÃ©sormais dâ€™effectuer ce processus de management de la donnÃ©e Ã  distance.

Le cloud couplÃ© Ã  une architecture sans serveur (serverless) offre de nombreux avantages aux entreprises et organisations tels queâ€¯:

- Un gain dâ€™efficacitÃ©â€¯: la couche de stockage et la couche de calcul sont dÃ©couplÃ©es, ce qui permet de conserver la quantitÃ© de data dans la couche de stockage pendant le temps nÃ©cessaire au calcul
- Un gain de temps : contrairement au dÃ©ploiement dâ€™un cluster gÃ©rÃ© qui peut prendre plusieurs heures voire jours avant dâ€™Ãªtre abouti, lâ€™installation dâ€™application Big Data sans serveur ne prend que quelques minutes
- Une tolÃ©rance aux pannes : par dÃ©faut, lâ€™architecture *serverless* non gÃ©rÃ©e tolÃ¨re les Ã©ventuelles pannes et incidents. Le contrat de service garantit une disponibilitÃ© accrue. Il nâ€™y a donc pas besoin dâ€™un administrateur.
- Une mise Ã  jour simplifiÃ©e et/ou automatiqueâ€¯: ees rÃ¨gles dÃ©finies de mise Ã  jour automatique permettent dâ€™adapter et dâ€™Ã©tendre lâ€™application en fonction de la charge de travail rÃ©duisant ainsi le coÃ»t de traitement de maniÃ¨re considÃ©rable.

#### 3.2.2 Le modÃ¨le de programmation MapReduce

Autour de 2003, les chercheurs de Google ont dÃ©veloppÃ© MapReduce.

Cette technique de programmation simplifie le traitement dâ€™ensembles de donnÃ©es en commenÃ§ant par rÃ©duire les donnÃ©es Ã  des sÃ©ries de couples Â« clÃ©/valeur Â», puis en procÃ©dant Ã  des calculs sur les donnÃ©es possÃ©dant des clÃ©s similaires, afin de tout rÃ©duire Ã  une valeur unique. Chaque Â« gros morceau Â» de donnÃ©es pouvait ainsi Ãªtre traitÃ© en parallÃ¨le sur des centaines voire des milliers de machines peu coÃ»teuses. Cette technique de traitement en parallÃ¨le sur des Ã©chelles massives a permis Ã  Google de gÃ©nÃ©rer des rÃ©sultats de recherche sur des volumes de donnÃ©es incroyablement plus grands quâ€™avant, et ce, en allant plus vite.

Le framework MapReduce est scindÃ© en deux espaces fonctionnels :

    Map, une fonction qui rÃ©partit le travail Ã  diffÃ©rents noeuds dans les grappes dâ€™ordinateurs.
    Reduce, une fonction qui rassemble le travail et rÃ©sume les rÃ©sultats dans une valeur simple.

![djo](https://www.lebigdata.fr/wp-content/uploads/2017/08/mapreduce-fonctionnement.png)

Un des avantages primaires de Map Reduce est quâ€™il est Â« fault-tolerant Â» ou tolÃ©rant aux pannes. Comment fait-il ? Il Â« monitore Â» chaque noeud (node) du cluster rÃ©guliÃ¨rement. Celui-ci est supposÃ© renvoyer pÃ©riodiquement un travail complet avec des mises Ã  jour des Â« status Â». Si un noeud reste silencieux plus que nÃ©cessaire, un master node le signale et rÃ©assigne le travail Ã  dâ€™autres noeuds du cluster.


#### 3.2.4. Les bases de donnÃ©es NoSQL

MÃªme avec Hadoop, il faut quand mÃªme un moyen de stocker et dâ€™accÃ©der aux donnÃ©es. Câ€™est typiquement ce Ã  quoi servent des NoSQL database telles que Mongo DB, CouchDG ou Cassandra, spÃ©cialisÃ©es dans le traitement des donnÃ©es non-structurÃ©es ou semi-structurÃ©es et distribuÃ©es Ã  travers de multiples machines.




Pour rÃ©ussir Ã  exploiter les Â« Big Data Â» techniquement, lâ€™idÃ©e nâ€™est plus de centraliser le stockage et le traitement des donnÃ©es sur un serveur, mais de distribuer leur stockage et de parallÃ©liser leur traitement sur plusieurs ordinateurs




## 4. Points importants Ã  retenir
Au-delÃ  des buzz words, l'analyse de donnÃ©es prend diffÃ©rentes formes et peut se rÃ©aliser Ã  diffÃ©rents niveaux. On peut distinguer deux types d'analyses : 
- l'analyse de donnÃ©es au travers de logiciels de *Business Intelligence* qui permet de faire parler les donnÃ©es, le plus souvent dÃ©jÃ  collectÃ©es et stockÃ©es dans lâ€™entreprise.
- lâ€™analytique Big Data qui nÃ©cessite lâ€™intervention de spÃ©cialistes et la mise en Å“uvre dâ€™une architecture informatique et dâ€™outils complexes. 


## 5. Pour aller plus loin


peut-Ãªtre mettre une blague ex : "si tu me crois pas qu'Hadoop est indispensable, cf https://www.decideo.fr/Les-6-competences-les-plus-recherchees-en-Big-Data_a10051.html"
